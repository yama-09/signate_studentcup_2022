{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ddea38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 3060\n",
      "fold 0 ================================================================================\n",
      "distilbert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cd40b6fd2aa4233b6b55e83abee3619",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d128aadd742240e9840f236978fe9fa5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12bf01af1b6f4262881580fb131d566d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d16365365fd4bca83aa4222b3d91446",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9486443797747294  Acc: 0.631578947368421  f1: 0.48167283236711556  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d77476ac94049f9acf965e6964f65b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5725fd4227425291932f0349e12a90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7394933700561523  Acc: 0.7039473684210527  f1: 0.5470313541035585  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "67b5216308914cd494a2befaf7278d7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec07c7cfe3be461d9cd9ccd05be28990",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6797496477762858  Acc: 0.7368421052631579  f1: 0.5959795115532821  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2ffe4af7a2d4190b111b7b525e9a354",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e3bdedf4021945d1b0e87fe38ba50066",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6378481388092041  Acc: 0.7532894736842105  f1: 0.7151294325077246  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81e59df389534ccbb10c612c18249a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "73ad47a14dde4eeb87bd2d5e99d12069",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7062721451123556  Acc: 0.7302631578947368  f1: 0.6534326956574272  \n",
      "\n",
      "<fold=0> best score: 0.7151294325077246\n",
      "\n",
      "fold 1 ================================================================================\n",
      "distilbert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27e94bf53fd64ac7a8ba264bf69444c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec74a92abe4f42a5bbd842ccb399d462",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dce53448cec24104bf488079be03f823",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbb6d022d0ee4fa98e12431b35e8db2d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8324923515319824  Acc: 0.6831683168316832  f1: 0.5285735998377377  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "05cf5168809b47bca26dfc96115ad95a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4f1c9a8f81941a4908fc96eda67c1b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7701610128084818  Acc: 0.6864686468646864  f1: 0.5291787507957841  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61438f3458ff49f29fcac334fc26e59b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3784a67fac7d40c5aca0c053d36602a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7688472469647726  Acc: 0.7161716171617162  f1: 0.6540723118042706  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4f090e8a1b745ff8c08a46925a06165",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f12a173290b5430abb557393855910dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7940248052279154  Acc: 0.7458745874587459  f1: 0.6947178080718454  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bebe8ea51764531aa8810541fbea2d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f0b097737d34fce95d7c5461e879d4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9391235113143921  Acc: 0.7062706270627063  f1: 0.6457201399161682  \n",
      "\n",
      "<fold=1> best score: 0.6947178080718454\n",
      "\n",
      "fold 2 ================================================================================\n",
      "distilbert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3637c29c1d514e3ba3b14ab1cac840ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cfdf1a93e2e241bfaf164d487b69f755",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8b81a776154aa9913ae6b3df3f0c16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b6f945f8964cab898b17bc4a5e84cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7523372371991476  Acc: 0.7095709570957096  f1: 0.539507252007252  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42fb24155cca442cb03eb24dc05f3405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8c07489c00e244b88a594fe2530fff3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6630420684814453  Acc: 0.7491749174917491  f1: 0.5723870673422242  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2b158d23bcb4148a736cd68f713c958",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4587838a3de04f878cbe08c98f80742e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6108338634173075  Acc: 0.7623762376237624  f1: 0.6337269066301324  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b2e7de28eb84ddaa99417bb0ef17743",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91e1992ef37a4cf4bd7239ddc10f2fc3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6076400279998779  Acc: 0.7788778877887789  f1: 0.6476128157784828  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf52144eb309427baac67d9156052299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3741d4f6d8044eda34beef1f76faefb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6555035710334778  Acc: 0.759075907590759  f1: 0.6636026136026136  model saving!\n",
      "\n",
      "<fold=2> best score: 0.6636026136026136\n",
      "\n",
      "fold 3 ================================================================================\n",
      "distilbert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bc89bbb8a184265b4d95a0bd44655e0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7d1c0ec251041bd951382ea42a4bae6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9118e689abca485d96bf9f4d5273c81e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cb327f323ee48a2b607e49bde04b66a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8446412881215414  Acc: 0.6237623762376238  f1: 0.47940227461504065  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "211def31bfd247f29a783a2933303478",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5e56b1f3fad4a12957823c75cd2d037",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6641039450963339  Acc: 0.7260726072607261  f1: 0.5623937202045071  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6b04757094094f82bf533ed3823f6e28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f82dfd00b06848aa8e0d2beeccaaa2c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6304879387219747  Acc: 0.7458745874587459  f1: 0.6226798411895782  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27ef63f035174eeea9438b8ced87f798",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec1c209d1fec404c8e965b3e989038c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6535021662712097  Acc: 0.7788778877887789  f1: 0.7028710123328797  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b54d47ff2f604753856e128e53784f82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1b5ecce67994550ae87f89c98e9817b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6985668937365214  Acc: 0.7557755775577558  f1: 0.6974066555286321  \n",
      "\n",
      "<fold=3> best score: 0.7028710123328797\n",
      "\n",
      "fold 4 ================================================================================\n",
      "distilbert-base-uncased\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "302e9611629340469f82f3782ae69b35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "664bb48946194310a367799051575d55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8be1acf12f4140aa2a44edcb38be55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e347c1da43f64421809da3cd0f355bc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7636197209358215  Acc: 0.7128712871287128  f1: 0.5493500240731825  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38838cc59c6e460cb16ac887f06c59d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1b77c1f41fb4fcaa12a95d44c484c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6783156196276346  Acc: 0.7557755775577558  f1: 0.5837947960731104  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5879178a0ea54b6db1d6ce2e569ae2b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fccdabdd0c5043668572e4f0a8c28824",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6681878368059794  Acc: 0.7557755775577558  f1: 0.6438033320910459  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e69a2d398c27431a91f7acd3cd19809a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f353dea0df449e1a6684ce421a86cb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6766132712364197  Acc: 0.7524752475247525  f1: 0.6814453035288437  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87899593a30e40228802f2c2c362d8e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b08c7a68aafb448ea102560eafad6d90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6984226306279501  Acc: 0.7425742574257426  f1: 0.6319138881960035  \n",
      "\n",
      "<fold=4> best score: 0.6814453035288437\n",
      "\n",
      "CV: 0.6915532340087814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertModel: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.bias', 'vocab_projector.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias']\n",
      "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd3189ed890148ea8a6a9915410a3380",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9b1c4e9533b497f8466e0b094cf5eaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AdamW, AutoModel, AutoTokenizer\n",
    "import texthero as hero\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# seeds\n",
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "\n",
    "\n",
    "# config\n",
    "data_dir = os.path.join( \"input/\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAIN_FILE = os.path.join(data_dir, \"train_clean.csv\")\n",
    "TEST_FILE = os.path.join(data_dir, \"test_clean.csv\")\n",
    "MODELS_DIR = \"models/\"\n",
    "MODEL_NAME = 'distilbert-base-uncased'\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 128\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 5\n",
    "NUM_SPLITS = 5\n",
    "\n",
    "\n",
    "# dataset\n",
    "def make_folded_df(csv_file, num_splits=5):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    \n",
    "    df[\"jobflag\"] = df[\"jobflag\"] - 1\n",
    "    df[\"kfold\"] = np.nan\n",
    "    df = df.rename(columns={'jobflag': 'labels'})\n",
    "    label = df[\"labels\"].tolist()\n",
    "\n",
    "    skfold = StratifiedKFold(num_splits, shuffle=True, random_state=SEED)\n",
    "    for fold, (_, valid_indexes) in enumerate(skfold.split(range(len(label)), label)):\n",
    "        for i in valid_indexes:\n",
    "            df.iat[i,3] = fold\n",
    "    return df\n",
    "\n",
    "def make_dataset(df, tokenizer, device):\n",
    "    dataset = nlp.Dataset.from_pandas(df)\n",
    "    dataset = dataset.map(\n",
    "        lambda example: tokenizer(example[\"description\"],\n",
    "                                  padding=\"max_length\",\n",
    "                                  truncation=True,\n",
    "                                  max_length=128))\n",
    "    dataset.set_format(type='torch', \n",
    "                       columns=['input_ids', 'attention_mask', 'labels'], \n",
    "                       device=device)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert(\n",
    "                input_ids = input_ids,\n",
    "                attention_mask = attention_mask,\n",
    "                return_dict=False\n",
    "                )\n",
    "        output = output[0]\n",
    "        output = output[:, 0, :]\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        \n",
    "        #print(output.shape)\n",
    "        #print(output[:, 0, :].shape)\n",
    "        return output\n",
    "\n",
    "\n",
    "# training function\n",
    "def train_fn(dataloader, model, criterion, optimizer, scheduler, device, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    progress = tqdm(dataloader, total=len(dataloader))\n",
    "\n",
    "    for i, batch in enumerate(progress):\n",
    "        progress.set_description(f\"<Train> Epoch{epoch+1}\")\n",
    "\n",
    "        if len(batch.values())==4:\n",
    "            attention_mask, input_ids, labels, token_type_ids = batch.values()\n",
    "        else:\n",
    "            attention_mask, input_ids, labels = batch.values()\n",
    "            token_type_ids = None\n",
    "        del batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        del input_ids, attention_mask, token_type_ids\n",
    "        \n",
    "        #print(labels.shape)\n",
    "        #outputs = outputs[0]\n",
    "        \n",
    "        loss = criterion(outputs, labels)  # 損失を計算\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "        del outputs\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        del loss\n",
    "        total_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        all_labels += labels.tolist()\n",
    "        all_preds += preds.tolist()\n",
    "        del labels, preds\n",
    "\n",
    "        progress.set_postfix(loss=total_loss/(i+1), f1=f1_score(all_labels, all_preds, average=\"macro\"))\n",
    "\n",
    "    train_loss = total_loss / len(dataloader)\n",
    "    train_acc = total_corrects.double().cpu().detach().numpy() / len(dataloader.dataset)\n",
    "    train_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "\n",
    "def eval_fn(dataloader, model, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress = tqdm(dataloader, total=len(dataloader))\n",
    "        \n",
    "        for i, batch in enumerate(progress):\n",
    "            progress.set_description(f\"<Valid> Epoch{epoch+1}\")\n",
    "\n",
    "            if len(batch.values())==4:\n",
    "                attention_mask, input_ids, labels, token_type_ids = batch.values()\n",
    "            else:\n",
    "                attention_mask, input_ids, labels = batch.values()\n",
    "                token_type_ids = None\n",
    "            del batch\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            del input_ids, attention_mask, token_type_ids\n",
    "            \n",
    "            #outputs = outputs[0]\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            del outputs\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            del loss\n",
    "            total_corrects += torch.sum(preds == labels)\n",
    "\n",
    "            all_labels += labels.tolist()\n",
    "            all_preds += preds.tolist()\n",
    "            del labels, preds\n",
    "\n",
    "            progress.set_postfix(loss=total_loss/(i+1), f1=f1_score(all_labels, all_preds, average=\"macro\"))\n",
    "\n",
    "    valid_loss = total_loss / len(dataloader)\n",
    "    valid_acc = total_corrects.double().cpu().detach().numpy() / len(dataloader.dataset)\n",
    "\n",
    "    valid_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    return valid_loss, valid_acc, valid_f1\n",
    "\n",
    "\n",
    "def plot_training(train_losses, train_accs, train_f1s,\n",
    "                  valid_losses, valid_accs, valid_f1s,\n",
    "                  epoch, fold):\n",
    "    \n",
    "    loss_df = pd.DataFrame({\"Train\":train_losses,\n",
    "                            \"Valid\":valid_losses},\n",
    "                        index=range(1, epoch+2))\n",
    "    loss_ax = sns.lineplot(data=loss_df).get_figure()\n",
    "    loss_ax.savefig(f\"figures/loss_plot_fold={fold}.png\", dpi=300)\n",
    "    loss_ax.clf()\n",
    "\n",
    "    acc_df = pd.DataFrame({\"Train\":train_accs,\n",
    "                           \"Valid\":valid_accs},\n",
    "                          index=range(1, epoch+2))\n",
    "    acc_ax = sns.lineplot(data=acc_df).get_figure()\n",
    "    acc_ax.savefig(f\"figures/acc_plot_fold={fold}.png\", dpi=300)\n",
    "    acc_ax.clf()\n",
    "\n",
    "    f1_df = pd.DataFrame({\"Train\":train_f1s,\n",
    "                          \"Valid\":valid_f1s},\n",
    "                         index=range(1, epoch+2))\n",
    "    f1_ax = sns.lineplot(data=f1_df).get_figure()\n",
    "    f1_ax.savefig(f\"figures/f1_plot_fold={fold}.png\", dpi=300)\n",
    "    f1_ax.clf()\n",
    "\n",
    "def trainer(fold, df):\n",
    "    \n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "    \n",
    "    print(MODEL_NAME)\n",
    "    \n",
    "    train_dataset = make_dataset(train_df, tokenizer, DEVICE)\n",
    "    valid_dataset = make_dataset(valid_df, tokenizer, DEVICE)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    valid_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "\n",
    "    model = Classifier(MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100000, gamma=1.0)\n",
    "    # ダミーのスケジューラー\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_f1s = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    valid_f1s = []\n",
    "\n",
    "    best_loss = np.inf\n",
    "    best_acc = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_fn(train_dataloader, model, criterion, optimizer, scheduler, DEVICE, epoch)\n",
    "        valid_loss, valid_acc, valid_f1 = eval_fn(valid_dataloader, model, criterion, DEVICE, epoch)\n",
    "        print(f\"Loss: {valid_loss}  Acc: {valid_acc}  f1: {valid_f1}  \", end=\"\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        train_f1s.append(train_f1)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accs.append(valid_acc)\n",
    "        valid_f1s.append(valid_f1)\n",
    "\n",
    "        plot_training(train_losses, train_accs, train_f1s,\n",
    "                      valid_losses, valid_accs, valid_f1s,\n",
    "                      epoch, fold)\n",
    "        \n",
    "        best_loss = valid_loss if valid_loss < best_loss else best_loss\n",
    "        besl_acc = valid_acc if valid_acc > best_acc else best_acc\n",
    "        if valid_f1 > best_f1:\n",
    "            best_f1 = valid_f1\n",
    "            print(\"model saving!\", end=\"\")\n",
    "            torch.save(model.state_dict(), MODELS_DIR + f\"best_{MODEL_NAME}_{fold}.pth\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return best_f1\n",
    "\n",
    "\n",
    "# training\n",
    "df = make_folded_df(TRAIN_FILE, NUM_SPLITS)\n",
    "f1_scores = []\n",
    "for fold in range(NUM_SPLITS):\n",
    "    print(f\"fold {fold}\", \"=\"*80)\n",
    "    f1 = trainer(fold, df)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"<fold={fold}> best score: {f1}\\n\")\n",
    "\n",
    "cv = sum(f1_scores) / len(f1_scores)\n",
    "print(f\"CV: {cv}\")\n",
    "\n",
    "lines = \"\"\n",
    "for i, f1 in enumerate(f1_scores):\n",
    "    line = f\"fold={i}: {f1}\\n\"\n",
    "    lines += line\n",
    "lines += f\"CV    : {cv}\"\n",
    "with open(f\"result/{MODEL_NAME}_result.txt\", mode='w') as f:\n",
    "    f.write(lines)\n",
    "\n",
    "\n",
    "# inference\n",
    "models = []\n",
    "for fold in range(NUM_SPLITS):\n",
    "    model = Classifier(MODEL_NAME)\n",
    "    model.load_state_dict(torch.load(MODELS_DIR + f\"best_{MODEL_NAME}_{fold}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "test_df = pd.read_csv(TEST_FILE)\n",
    "\n",
    "\n",
    "test_df[\"labels\"] = -1\n",
    "test_dataset = make_dataset(test_df, tokenizer, DEVICE)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    progress = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    final_output = []\n",
    "\n",
    "    for batch in progress:\n",
    "        progress.set_description(\"<Test>\")\n",
    "\n",
    "        attention_mask, input_ids, labels = batch.values()\n",
    "        token_type_ids = None\n",
    "\n",
    "        outputs = []\n",
    "        for model in models:\n",
    "            output = model(input_ids, attention_mask, token_type_ids)\n",
    "            #output = output[0]\n",
    "            outputs.append(output)\n",
    "            \n",
    "        \n",
    "        outputs = sum(outputs) / len(outputs)\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu().detach().tolist()\n",
    "        outputs = np.argmax(outputs, axis=1)\n",
    "\n",
    "        final_output.extend(outputs)\n",
    "\n",
    "submit = pd.read_csv(os.path.join(data_dir, \"submit_sample.csv\"), names=[\"id\", \"labels\"])\n",
    "submit[\"labels\"] = final_output\n",
    "submit[\"labels\"] = submit[\"labels\"] + 1\n",
    "try:\n",
    "    submit.to_csv(\"./output/Distilbert_submission_cv{}.csv\".format(str(cv).replace(\".\", \"\")[:10]), index=False, header=False)\n",
    "except NameError:\n",
    "    submit.to_csv(\"./output/submission.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9aa1ff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "437bd187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

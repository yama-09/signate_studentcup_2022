{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ddea38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 3060\n",
      "fold 0 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f5411695cb246999db715615f93fd07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69b98702fdef495798ddfd723571d464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85ae2dbf234547a4808a6473c1ab6733",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e2ed29a73e54f108ca002f6f6806e06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5089432001113892  Acc: 0.8220757825370676  f1: 0.78549063097655  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45e5790502a24d39bca8e4aa7d46fe38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeefae5b4163481199fcb5e5c1038228",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4897942185401917  Acc: 0.8401976935749588  f1: 0.8278349877849817  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "323ee65c02d94874aa3548e98cc7b67c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f450ecc097584712a8cb8782cc119c5e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5089629292488098  Acc: 0.8352553542009885  f1: 0.78765044717482  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabf6fc61c4741a593ca6e04563d4bee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e624ff002a894b268bf46879e82c02f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.524033498764038  Acc: 0.8467874794069192  f1: 0.817538056560454  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec8a80b057b2433f9b620ade7f776f35",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "171649d3a0a8491582596f700bac55f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5388268440961838  Acc: 0.8632619439868204  f1: 0.8315078388631147  model saving!\n",
      "\n",
      "<fold=0> best score: 0.8315078388631147\n",
      "\n",
      "fold 1 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33419483c38e4d53b869aeb4b8f477e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce9ce033b59c4406b5480e34d354b4a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "407ec6df6aab449f94d90d8d2d127352",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b523610919414a8da27f9d40e8b74a82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5539555847644806  Acc: 0.800658978583196  f1: 0.7239946010113116  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b7ca9576774c4ef1bb717900aecca6a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fb8ba8768ac4c04abfc924b1a3c1b43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.511066448688507  Acc: 0.8039538714991763  f1: 0.7444081235220475  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e53397d5ed8a47898957ae84cb9d6ea2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c56803f2f762427dbb438644a400a1c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5111147075891495  Acc: 0.8154859967051071  f1: 0.7464313324016885  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4c12e159fd74e7ea91ac693061a10ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7fc9321b3704c419716bb5f9e7ec0d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6225999742746353  Acc: 0.8220757825370676  f1: 0.7789546285077811  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "482be257be7044a0814dfa8b62acda5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1c71f3238cd4c6494e7fb7cce7c1bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6286753609776496  Acc: 0.8121911037891268  f1: 0.7443688069852301  \n",
      "\n",
      "<fold=1> best score: 0.7789546285077811\n",
      "\n",
      "fold 2 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a5210e9770947899152c03718dbdacb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2426 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4c339cdc96c49178281bd859d854243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/607 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "be77168a81954378a98443fe5999d62f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a53c5f37e6384b0db966005a70a5adc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.45950919985771177  Acc: 0.828665568369028  f1: 0.696688421561518  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebdaa1496abe4d789b2673c972a33123",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c3bb01ae5f549ed959912f0b1159b9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.42364715933799746  Acc: 0.8500823723228995  f1: 0.8110460040003846  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25410d683029484cbed1668c2a9fca82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38a9a601489648a9890e4f26cfec22c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.519795161485672  Acc: 0.8105436573311368  f1: 0.7712600004027007  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5ba2905a387410d8ed13b35d9a0e09d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d71634e574bd42c995e2e3f58cce5780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.49212340712547303  Acc: 0.8401976935749588  f1: 0.7917577278559502  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97d5cc3ecce24c17b9feaf0b1f71f83f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7c4b287faf44aa48d70d2a336953b21",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5077079772949219  Acc: 0.8319604612850082  f1: 0.7799357864754008  \n",
      "\n",
      "<fold=2> best score: 0.8110460040003846\n",
      "\n",
      "fold 3 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "828b888d78ed4296b66c4d34e4165850",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1d12206e82444ab7da2fe7f2eeea70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/606 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e43bb9418be64da49e66469ca6c0e912",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b8f06c0c6774af2a03b770b458a3164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4847229480743408  Acc: 0.8366336633663366  f1: 0.6968075406678069  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f839ed6c8e124a67be61cf9896b35e42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca67ef1ba7c4410f8cb8b5264bb20af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4120050936937332  Acc: 0.8597359735973598  f1: 0.8075501741552512  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffceabc8e8164d86aef3690832ddd64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa8984abfdcc4e38985890f1b8e64fbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.3721938908100128  Acc: 0.8844884488448845  f1: 0.8327200732003059  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebf12ac4bd6e4309abc863a9b1bca481",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4736a72050ac4499b1636e16bceb52dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.39284360110759736  Acc: 0.8679867986798679  f1: 0.8258821443027093  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b9b390330b448288db64cd19bc42d14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a761ed10f3d04b69b7afdc46d52efbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4976678937673569  Acc: 0.8597359735973598  f1: 0.8357389864067937  model saving!\n",
      "\n",
      "<fold=3> best score: 0.8357389864067937\n",
      "\n",
      "fold 4 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f90a587a2ab04159968ec3ff66e0891f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2427 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "254f5af8e69e4bcc8e800b7804884b8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/606 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b7aabc4f273469daefb6ba6f2904c77",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd028ff9680a46f49c92403d9566c638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4674301266670227  Acc: 0.8135313531353136  f1: 0.7109500715663224  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8db3fcc78c4f4d96b63ac16b9b74b2e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b39c88437ef48e6a696cf0978b4d49e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4831689357757568  Acc: 0.8234323432343235  f1: 0.7910954492944154  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d184d1af3b7e48e4a17997de0969c680",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "907ab7e1967842458a2794b94bdf3890",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.4802979439496994  Acc: 0.8399339933993399  f1: 0.7937137929422423  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "64d2791c0b064d599517c45177376075",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a85375d0d6eb4534965bd81dfbf584b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5206526637077331  Acc: 0.8382838283828383  f1: 0.7838051218694727  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d63d54a1244d48259ba342b189c495a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/76 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5cd641034ffa4768a868052c91a6ba10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.5255190283060074  Acc: 0.858085808580858  f1: 0.8105744035300384  model saving!\n",
      "\n",
      "<fold=4> best score: 0.8105744035300384\n",
      "\n",
      "CV: 0.8135643722616225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b58379e3f79401e81c151db6e0108ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8515c69b2e914639a339e0b9f0d00b12",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AdamW, AutoModel, AutoTokenizer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# seeds\n",
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "\n",
    "\n",
    "# config\n",
    "data_dir = os.path.join( \"input/\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAIN_FILE = os.path.join(data_dir, \"data.csv\")\n",
    "TEST_FILE = os.path.join(data_dir, \"test.csv\")\n",
    "MODELS_DIR = \"models/\"\n",
    "MODEL_NAME = 'bert-base-uncased' # bert-base-uncased\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 128\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 5\n",
    "NUM_SPLITS = 5\n",
    "\n",
    "\n",
    "# dataset\n",
    "def make_folded_df(csv_file, num_splits=5):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df[\"jobflag\"] = df[\"jobflag\"] - 1\n",
    "    df[\"kfold\"] = np.nan\n",
    "    df = df.rename(columns={'jobflag': 'labels'})\n",
    "    label = df[\"labels\"].tolist()\n",
    "\n",
    "    skfold = StratifiedKFold(num_splits, shuffle=True, random_state=SEED)\n",
    "    for fold, (_, valid_indexes) in enumerate(skfold.split(range(len(label)), label)):\n",
    "        for i in valid_indexes:\n",
    "            df.iat[i,3] = fold\n",
    "    return df\n",
    "\n",
    "def make_dataset(df, tokenizer, device):\n",
    "    dataset = nlp.Dataset.from_pandas(df)\n",
    "    dataset = dataset.map(\n",
    "        lambda example: tokenizer(example[\"description\"],\n",
    "                                  padding=\"max_length\",\n",
    "                                  truncation=True,\n",
    "                                  max_length=128))\n",
    "    dataset.set_format(type='torch', \n",
    "                       columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'], \n",
    "                       device=device)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# model\n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output, _ = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "        return_dict=False)\n",
    "        #print(output)\n",
    "        output = output[:, 0, :]\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# training function\n",
    "def train_fn(dataloader, model, criterion, optimizer, scheduler, device, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    progress = tqdm(dataloader, total=len(dataloader))\n",
    "\n",
    "    for i, batch in enumerate(progress):\n",
    "        progress.set_description(f\"<Train> Epoch{epoch+1}\")\n",
    "\n",
    "        attention_mask, input_ids, labels, token_type_ids = batch.values()\n",
    "        del batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        del input_ids, attention_mask, token_type_ids\n",
    "        \n",
    "        #print(labels.shape)\n",
    "        #print(outputs)\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs, labels)  # 損失を計算\n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "        del outputs\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        del loss\n",
    "        total_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        all_labels += labels.tolist()\n",
    "        all_preds += preds.tolist()\n",
    "        del labels, preds\n",
    "\n",
    "        progress.set_postfix(loss=total_loss/(i+1), f1=f1_score(all_labels, all_preds, average=\"macro\"))\n",
    "\n",
    "    train_loss = total_loss / len(dataloader)\n",
    "    train_acc = total_corrects.double().cpu().detach().numpy() / len(dataloader.dataset)\n",
    "    train_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "\n",
    "def eval_fn(dataloader, model, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress = tqdm(dataloader, total=len(dataloader))\n",
    "        \n",
    "        for i, batch in enumerate(progress):\n",
    "            progress.set_description(f\"<Valid> Epoch{epoch+1}\")\n",
    "\n",
    "            attention_mask, input_ids, labels, token_type_ids = batch.values()\n",
    "            del batch\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            del input_ids, attention_mask, token_type_ids\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            del outputs\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            del loss\n",
    "            total_corrects += torch.sum(preds == labels)\n",
    "\n",
    "            all_labels += labels.tolist()\n",
    "            all_preds += preds.tolist()\n",
    "            del labels, preds\n",
    "\n",
    "            progress.set_postfix(loss=total_loss/(i+1), f1=f1_score(all_labels, all_preds, average=\"macro\"))\n",
    "\n",
    "    valid_loss = total_loss / len(dataloader)\n",
    "    valid_acc = total_corrects.double().cpu().detach().numpy() / len(dataloader.dataset)\n",
    "\n",
    "    valid_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    return valid_loss, valid_acc, valid_f1\n",
    "\n",
    "\n",
    "def plot_training(train_losses, train_accs, train_f1s,\n",
    "                  valid_losses, valid_accs, valid_f1s,\n",
    "                  epoch, fold):\n",
    "    \n",
    "    loss_df = pd.DataFrame({\"Train\":train_losses,\n",
    "                            \"Valid\":valid_losses},\n",
    "                        index=range(1, epoch+2))\n",
    "    loss_ax = sns.lineplot(data=loss_df).get_figure()\n",
    "    loss_ax.savefig(f\"figures/loss_plot_fold={fold}.png\", dpi=300)\n",
    "    loss_ax.clf()\n",
    "\n",
    "    acc_df = pd.DataFrame({\"Train\":train_accs,\n",
    "                           \"Valid\":valid_accs},\n",
    "                          index=range(1, epoch+2))\n",
    "    acc_ax = sns.lineplot(data=acc_df).get_figure()\n",
    "    acc_ax.savefig(f\"figures/acc_plot_fold={fold}.png\", dpi=300)\n",
    "    acc_ax.clf()\n",
    "\n",
    "    f1_df = pd.DataFrame({\"Train\":train_f1s,\n",
    "                          \"Valid\":valid_f1s},\n",
    "                         index=range(1, epoch+2))\n",
    "    f1_ax = sns.lineplot(data=f1_df).get_figure()\n",
    "    f1_ax.savefig(f\"figures/f1_plot_fold={fold}.png\", dpi=300)\n",
    "    f1_ax.clf()\n",
    "\n",
    "def trainer(fold, df):\n",
    "    \n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    train_dataset = make_dataset(train_df, tokenizer, DEVICE)\n",
    "    valid_dataset = make_dataset(valid_df, tokenizer, DEVICE)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    valid_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "\n",
    "    model = Classifier(MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100000, gamma=1.0)\n",
    "    # ダミーのスケジューラー\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_f1s = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    valid_f1s = []\n",
    "\n",
    "    best_loss = np.inf\n",
    "    best_acc = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_fn(train_dataloader, model, criterion, optimizer, scheduler, DEVICE, epoch)\n",
    "        valid_loss, valid_acc, valid_f1 = eval_fn(valid_dataloader, model, criterion, DEVICE, epoch)\n",
    "        print(f\"Loss: {valid_loss}  Acc: {valid_acc}  f1: {valid_f1}  \", end=\"\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        train_f1s.append(train_f1)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accs.append(valid_acc)\n",
    "        valid_f1s.append(valid_f1)\n",
    "\n",
    "        plot_training(train_losses, train_accs, train_f1s,\n",
    "                      valid_losses, valid_accs, valid_f1s,\n",
    "                      epoch, fold)\n",
    "        \n",
    "        best_loss = valid_loss if valid_loss < best_loss else best_loss\n",
    "        besl_acc = valid_acc if valid_acc > best_acc else best_acc\n",
    "        if valid_f1 > best_f1:\n",
    "            best_f1 = valid_f1\n",
    "            print(\"model saving!\", end=\"\")\n",
    "            torch.save(model.state_dict(), MODELS_DIR + f\"best_{MODEL_NAME}_{fold}.pth\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return best_f1\n",
    "\n",
    "\n",
    "# training\n",
    "df = make_folded_df(TRAIN_FILE, NUM_SPLITS)\n",
    "f1_scores = []\n",
    "for fold in range(NUM_SPLITS):\n",
    "    print(f\"fold {fold}\", \"=\"*80)\n",
    "    f1 = trainer(fold, df)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"<fold={fold}> best score: {f1}\\n\")\n",
    "\n",
    "cv = sum(f1_scores) / len(f1_scores)\n",
    "print(f\"CV: {cv}\")\n",
    "\n",
    "lines = \"\"\n",
    "for i, f1 in enumerate(f1_scores):\n",
    "    line = f\"fold={i}: {f1}\\n\"\n",
    "    lines += line\n",
    "lines += f\"CV    : {cv}\"\n",
    "with open(f\"result/{MODEL_NAME}_result.txt\", mode='w') as f:\n",
    "    f.write(lines)\n",
    "\n",
    "\n",
    "# inference\n",
    "models = []\n",
    "for fold in range(NUM_SPLITS):\n",
    "    model = Classifier(MODEL_NAME)\n",
    "    model.load_state_dict(torch.load(MODELS_DIR + f\"best_{MODEL_NAME}_{fold}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "test_df = pd.read_csv(TEST_FILE)\n",
    "test_df[\"labels\"] = -1\n",
    "test_dataset = make_dataset(test_df, tokenizer, DEVICE)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    progress = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    final_output = []\n",
    "\n",
    "    for batch in progress:\n",
    "        progress.set_description(\"<Test>\")\n",
    "\n",
    "        attention_mask, input_ids, labels, token_type_ids = batch.values()\n",
    "\n",
    "        outputs = []\n",
    "        for model in models:\n",
    "            output = model(input_ids, attention_mask, token_type_ids)\n",
    "            outputs.append(output)\n",
    "\n",
    "        outputs = sum(outputs) / len(outputs)\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu().detach().tolist()\n",
    "        outputs = np.argmax(outputs, axis=1)\n",
    "\n",
    "        final_output.extend(outputs)\n",
    "\n",
    "submit = pd.read_csv(os.path.join(data_dir, \"submit_sample.csv\"), names=[\"id\", \"labels\"])\n",
    "submit[\"labels\"] = final_output\n",
    "submit[\"labels\"] = submit[\"labels\"] + 1\n",
    "try:\n",
    "    submit.to_csv(\"./output/Bert_submission_cv{}.csv\".format(str(cv).replace(\".\", \"\")[:10]), index=False, header=False)\n",
    "except NameError:\n",
    "    submit.to_csv(\"./output/submission.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9aa1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77d44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ddea38a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: NVIDIA GeForce RTX 3060\n",
      "fold 0 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e04fc86a3a64104be83338d010fb7cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1212 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c054264feefc4f369ba9804c15d79da8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/304 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e0261f7d669242a2abbde725ada2fc51",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8916ea63b144ec7bac3d22f8bd941da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1237510045369465  Acc: 0.47368421052631576  f1: 0.3676968030660097  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49a750ed01d74868b2a561c64c94f4f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "370ea8f303f34f83a1d4bf9f8426fa6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7623845934867859  Acc: 0.7171052631578947  f1: 0.5538115952928511  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0efe74fa0c5c4fdf8c92416bfa1c6d94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b36e5c1bc81e4bbb86805e2564b82372",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7317402760187784  Acc: 0.7335526315789473  f1: 0.5913289793289033  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12d315f3ba974acf9d21fa4f2367052e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bf58194bec4a4ab89c3a7fdfb49a47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.787108321984609  Acc: 0.7269736842105263  f1: 0.6587665056886162  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19fb439d933d42fb9ba66449fc4f35ba",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "124dd85507de462588bc4a9f9815e63b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8262717922528585  Acc: 0.75  f1: 0.6767926974295786  model saving!\n",
      "\n",
      "<fold=0> best score: 0.6767926974295786\n",
      "\n",
      "fold 1 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f71f52c739b64737b2f779fcf60a1fc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "429b0fd28b7b427e878c8e4ea032d949",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8eae7ce2d5a413f95f5bbc2e7711faa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0819fd7b02ce41d39cb7137aa288cbb0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.163838783899943  Acc: 0.44884488448844884  f1: 0.2925639214684984  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e2b42ac14d54527ba87bc6c341bd923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f962125fdb884e9f8cad15e169ef1704",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8823564052581787  Acc: 0.6270627062706271  f1: 0.48070274761079845  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7eefd133e4746e9ad1cbc9697ca8e58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53260416c0bd46a6b160301b8b88ba5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7559326489766439  Acc: 0.6897689768976898  f1: 0.5582365574992488  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af377e71150042b5b31f24001a451299",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4267de0dbbb14b25a8c7cc3db21830c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7504158218701681  Acc: 0.7095709570957096  f1: 0.6516128300964366  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20fe325891c44a37a23e4127c4d03386",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff488f391d34f99b6aecd53fd6d9ff5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7189640800158182  Acc: 0.7458745874587459  f1: 0.7022846889952153  model saving!\n",
      "\n",
      "<fold=1> best score: 0.7022846889952153\n",
      "\n",
      "fold 2 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3d75ad5d91d490aa6a3afd743607510",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed45681a36134009a7b982e05b2d224c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "524b259b3b734cd8a8d8d62903d332d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24d65f0bae7a4f9e9d2fbd32538b1ee1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.1177669763565063  Acc: 0.5643564356435643  f1: 0.41123264746070204  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d2c4bec7bc4a549cd2a250397f2a8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95252a2f830746e5896018f0a80797c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7058261831601461  Acc: 0.7227722772277227  f1: 0.5553811750350308  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20bbc7069ebf459e9af339f48e6b20b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "368d765848e843deae0f2874ce80efb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6734973986943563  Acc: 0.7458745874587459  f1: 0.5977589018962258  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e0f617069f4f29a86a0ec8b408da27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4ac435adb945158602173273f13420",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.676105817159017  Acc: 0.7623762376237624  f1: 0.6744390895186458  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7537ccf50ee480b8a633fa4f886f302",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19a021bb9ca24c23b99e880fc46b387e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8473108410835266  Acc: 0.735973597359736  f1: 0.6233494335725666  \n",
      "\n",
      "<fold=2> best score: 0.6744390895186458\n",
      "\n",
      "fold 3 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d17527aed0d40c8a9e69f05f62e7c8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cce508dcbedf4656a0a117308092d884",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bfb15a9236f346ee805653b1c4e32c6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e37e4e2002094cd792c411d5087bf907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 1.2060503164927165  Acc: 0.43564356435643564  f1: 0.2654761904761905  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "925ee8b8d3e642bbb9f20dc0e9de20cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23797e6b510540e8bb7c2d367a91b67a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7718560298283895  Acc: 0.66996699669967  f1: 0.5135531135531135  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47bb34fd109e4171bd04279792b79c2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764d7529b9dc410497e50f5cd5e14c5d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6919642090797424  Acc: 0.7095709570957096  f1: 0.5456587935721818  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e01477239094d8fbc4a524a9205b126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd4aedb4bd9e414e89b81d450bb7d156",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7191286484400431  Acc: 0.7128712871287128  f1: 0.5978267900681693  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d13ad6232f14043afe205d3f488380a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3aadc6e64b454c9491334d0fcc1728f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.8203635215759277  Acc: 0.7161716171617162  f1: 0.6618755221386801  model saving!\n",
      "\n",
      "<fold=3> best score: 0.6618755221386801\n",
      "\n",
      "fold 4 ================================================================================\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99c2c6f40f06478da8bfc1e195627a0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1213 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f19865dac7749faae0140e8281f3e09",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/303 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbb94d4072f04bb2a44d0f1b27e31c3b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a4c664ec7c640d793f77c1003fdbbc4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.9976415236790975  Acc: 0.6171617161716172  f1: 0.4722519451770044  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cedfcbfbd51440bb82b23096197979b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f9e67ef7f4184161831e94cf7f4f647c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7249458233515421  Acc: 0.7293729372937293  f1: 0.5668697403861995  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff620ca075894e5a88a18020b70accbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9363d42f19af4ec2beedf94d10a68801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.7462559541066488  Acc: 0.7095709570957096  f1: 0.5508066143304661  \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4342a62c0c1c42d1890ca84cfa14a3cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f4962d80e264cb9acd04c898322785c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6765591899553934  Acc: 0.7491749174917491  f1: 0.6930249291245449  model saving!\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d3b62bff25242a8ab4479649ed41d57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8ddb6c9e744478e95f67ca58a696bf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.6690731048583984  Acc: 0.7260726072607261  f1: 0.6587589126559714  \n",
      "\n",
      "<fold=4> best score: 0.6930249291245449\n",
      "\n",
      "CV: 0.681683385441333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of the model checkpoint at xlnet-base-cased were not used when initializing XLNetModel: ['lm_loss.bias', 'lm_loss.weight']\n",
      "- This IS expected if you are initializing XLNetModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing XLNetModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ee108438d8d4d469f5bd90a8725c282",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1517 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d286d4084c7f47d8aa50976b5d3633e9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/12 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import collections\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nlp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, confusion_matrix, f1_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm.notebook import tqdm\n",
    "from transformers import AdamW, AutoModel, AutoTokenizer\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "# seeds\n",
    "SEED = 42\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "seed_everything(SEED)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    current_device = torch.cuda.current_device()\n",
    "    print(\"Device:\", torch.cuda.get_device_name(current_device))\n",
    "\n",
    "\n",
    "# config\n",
    "data_dir = os.path.join( \"input/\")\n",
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "TRAIN_FILE = os.path.join(data_dir, \"train.csv\")\n",
    "TEST_FILE = os.path.join(data_dir, \"test.csv\")\n",
    "MODELS_DIR = \"models/\"\n",
    "MODEL_NAME = 'xlnet-base-cased'\n",
    "TRAIN_BATCH_SIZE = 32\n",
    "VALID_BATCH_SIZE = 128\n",
    "NUM_CLASSES = 4\n",
    "EPOCHS = 5\n",
    "NUM_SPLITS = 5\n",
    "\n",
    "\n",
    "# dataset\n",
    "def make_folded_df(csv_file, num_splits=5):\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df[\"jobflag\"] = df[\"jobflag\"] - 1\n",
    "    df[\"kfold\"] = np.nan\n",
    "    df = df.rename(columns={'jobflag': 'labels'})\n",
    "    label = df[\"labels\"].tolist()\n",
    "\n",
    "    skfold = StratifiedKFold(num_splits, shuffle=True, random_state=SEED)\n",
    "    for fold, (_, valid_indexes) in enumerate(skfold.split(range(len(label)), label)):\n",
    "        for i in valid_indexes:\n",
    "            df.iat[i,3] = fold\n",
    "    return df\n",
    "\n",
    "def make_dataset(df, tokenizer, device):\n",
    "    dataset = nlp.Dataset.from_pandas(df)\n",
    "    dataset = dataset.map(\n",
    "        lambda example: tokenizer(example[\"description\"],\n",
    "                                  padding=\"max_length\",\n",
    "                                  truncation=True,\n",
    "                                  max_length=128))\n",
    "    dataset.set_format(type='torch', \n",
    "                       columns=['input_ids', 'token_type_ids', 'attention_mask', 'labels'], \n",
    "                       device=device)\n",
    "    return dataset\n",
    "\n",
    "\n",
    "# model\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, model_name, num_classes=4):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = AutoModel.from_pretrained(model_name)\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        self.linear = nn.Linear(768, num_classes)\n",
    "        nn.init.normal_(self.linear.weight, std=0.02)\n",
    "        nn.init.zeros_(self.linear.bias)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids):\n",
    "        output = self.bert(\n",
    "            input_ids = input_ids,\n",
    "            attention_mask = attention_mask,\n",
    "            token_type_ids = token_type_ids,\n",
    "        return_dict=False)\n",
    "        output = output[0]\n",
    "        output = output[:, 0, :]\n",
    "        output = self.dropout(output)\n",
    "        output = self.linear(output)\n",
    "        return output\n",
    "\n",
    "\n",
    "# training function\n",
    "def train_fn(dataloader, model, criterion, optimizer, scheduler, device, epoch):\n",
    "    \n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    progress = tqdm(dataloader, total=len(dataloader))\n",
    "\n",
    "    for i, batch in enumerate(progress):\n",
    "        progress.set_description(f\"<Train> Epoch{epoch+1}\")\n",
    "\n",
    "        attention_mask, input_ids, labels, token_type_ids = batch.values()\n",
    "        del batch\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "        del input_ids, attention_mask, token_type_ids\n",
    "        \n",
    "        #print(labels.shape)\n",
    "        #print(outputs)\n",
    "        \n",
    "        \n",
    "        loss = criterion(outputs, labels)  # 損失を計算\n",
    "        _, preds = torch.max(outputs, 1)  # ラベルを予測\n",
    "        del outputs\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        del loss\n",
    "        total_corrects += torch.sum(preds == labels)\n",
    "\n",
    "        all_labels += labels.tolist()\n",
    "        all_preds += preds.tolist()\n",
    "        del labels, preds\n",
    "\n",
    "        progress.set_postfix(loss=total_loss/(i+1), f1=f1_score(all_labels, all_preds, average=\"macro\"))\n",
    "\n",
    "    train_loss = total_loss / len(dataloader)\n",
    "    train_acc = total_corrects.double().cpu().detach().numpy() / len(dataloader.dataset)\n",
    "    train_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    return train_loss, train_acc, train_f1\n",
    "\n",
    "\n",
    "def eval_fn(dataloader, model, criterion, device, epoch):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_corrects = 0\n",
    "    all_labels = []\n",
    "    all_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        progress = tqdm(dataloader, total=len(dataloader))\n",
    "        \n",
    "        for i, batch in enumerate(progress):\n",
    "            progress.set_description(f\"<Valid> Epoch{epoch+1}\")\n",
    "\n",
    "            attention_mask, input_ids, labels, token_type_ids = batch.values()\n",
    "            del batch\n",
    "\n",
    "            outputs = model(input_ids, attention_mask, token_type_ids)\n",
    "            del input_ids, attention_mask, token_type_ids\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            del outputs\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            del loss\n",
    "            total_corrects += torch.sum(preds == labels)\n",
    "\n",
    "            all_labels += labels.tolist()\n",
    "            all_preds += preds.tolist()\n",
    "            del labels, preds\n",
    "\n",
    "            progress.set_postfix(loss=total_loss/(i+1), f1=f1_score(all_labels, all_preds, average=\"macro\"))\n",
    "\n",
    "    valid_loss = total_loss / len(dataloader)\n",
    "    valid_acc = total_corrects.double().cpu().detach().numpy() / len(dataloader.dataset)\n",
    "\n",
    "    valid_f1 = f1_score(all_labels, all_preds, average=\"macro\")\n",
    "\n",
    "    return valid_loss, valid_acc, valid_f1\n",
    "\n",
    "\n",
    "def plot_training(train_losses, train_accs, train_f1s,\n",
    "                  valid_losses, valid_accs, valid_f1s,\n",
    "                  epoch, fold):\n",
    "    \n",
    "    loss_df = pd.DataFrame({\"Train\":train_losses,\n",
    "                            \"Valid\":valid_losses},\n",
    "                        index=range(1, epoch+2))\n",
    "    loss_ax = sns.lineplot(data=loss_df).get_figure()\n",
    "    loss_ax.savefig(f\"figures/loss_plot_fold={fold}.png\", dpi=300)\n",
    "    loss_ax.clf()\n",
    "\n",
    "    acc_df = pd.DataFrame({\"Train\":train_accs,\n",
    "                           \"Valid\":valid_accs},\n",
    "                          index=range(1, epoch+2))\n",
    "    acc_ax = sns.lineplot(data=acc_df).get_figure()\n",
    "    acc_ax.savefig(f\"figures/acc_plot_fold={fold}.png\", dpi=300)\n",
    "    acc_ax.clf()\n",
    "\n",
    "    f1_df = pd.DataFrame({\"Train\":train_f1s,\n",
    "                          \"Valid\":valid_f1s},\n",
    "                         index=range(1, epoch+2))\n",
    "    f1_ax = sns.lineplot(data=f1_df).get_figure()\n",
    "    f1_ax.savefig(f\"figures/f1_plot_fold={fold}.png\", dpi=300)\n",
    "    f1_ax.clf()\n",
    "\n",
    "def trainer(fold, df):\n",
    "    \n",
    "    train_df = df[df.kfold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.kfold == fold].reset_index(drop=True)\n",
    "\n",
    "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "    train_dataset = make_dataset(train_df, tokenizer, DEVICE)\n",
    "    valid_dataset = make_dataset(valid_df, tokenizer, DEVICE)\n",
    "\n",
    "    train_dataloader = torch.utils.data.DataLoader(\n",
    "        train_dataset, batch_size=TRAIN_BATCH_SIZE, shuffle=True\n",
    "    )\n",
    "    valid_dataloader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False\n",
    "    )\n",
    "\n",
    "    model = Classifier(MODEL_NAME, num_classes=NUM_CLASSES)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=100000, gamma=1.0)\n",
    "    # ダミーのスケジューラー\n",
    "\n",
    "    train_losses = []\n",
    "    train_accs = []\n",
    "    train_f1s = []\n",
    "    valid_losses = []\n",
    "    valid_accs = []\n",
    "    valid_f1s = []\n",
    "\n",
    "    best_loss = np.inf\n",
    "    best_acc = 0\n",
    "    best_f1 = 0\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        train_loss, train_acc, train_f1 = train_fn(train_dataloader, model, criterion, optimizer, scheduler, DEVICE, epoch)\n",
    "        valid_loss, valid_acc, valid_f1 = eval_fn(valid_dataloader, model, criterion, DEVICE, epoch)\n",
    "        print(f\"Loss: {valid_loss}  Acc: {valid_acc}  f1: {valid_f1}  \", end=\"\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        train_f1s.append(train_f1)\n",
    "        valid_losses.append(valid_loss)\n",
    "        valid_accs.append(valid_acc)\n",
    "        valid_f1s.append(valid_f1)\n",
    "\n",
    "        plot_training(train_losses, train_accs, train_f1s,\n",
    "                      valid_losses, valid_accs, valid_f1s,\n",
    "                      epoch, fold)\n",
    "        \n",
    "        best_loss = valid_loss if valid_loss < best_loss else best_loss\n",
    "        besl_acc = valid_acc if valid_acc > best_acc else best_acc\n",
    "        if valid_f1 > best_f1:\n",
    "            best_f1 = valid_f1\n",
    "            print(\"model saving!\", end=\"\")\n",
    "            torch.save(model.state_dict(), MODELS_DIR + f\"best_{MODEL_NAME}_{fold}.pth\")\n",
    "        print(\"\\n\")\n",
    "\n",
    "    return best_f1\n",
    "\n",
    "\n",
    "# training\n",
    "df = make_folded_df(TRAIN_FILE, NUM_SPLITS)\n",
    "f1_scores = []\n",
    "for fold in range(NUM_SPLITS):\n",
    "    print(f\"fold {fold}\", \"=\"*80)\n",
    "    f1 = trainer(fold, df)\n",
    "    f1_scores.append(f1)\n",
    "    print(f\"<fold={fold}> best score: {f1}\\n\")\n",
    "\n",
    "cv = sum(f1_scores) / len(f1_scores)\n",
    "print(f\"CV: {cv}\")\n",
    "\n",
    "lines = \"\"\n",
    "for i, f1 in enumerate(f1_scores):\n",
    "    line = f\"fold={i}: {f1}\\n\"\n",
    "    lines += line\n",
    "lines += f\"CV    : {cv}\"\n",
    "with open(f\"result/{MODEL_NAME}_result.txt\", mode='w') as f:\n",
    "    f.write(lines)\n",
    "\n",
    "\n",
    "# inference\n",
    "models = []\n",
    "for fold in range(NUM_SPLITS):\n",
    "    model = Classifier(MODEL_NAME)\n",
    "    model.load_state_dict(torch.load(MODELS_DIR + f\"best_{MODEL_NAME}_{fold}.pth\"))\n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    models.append(model)\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
    "test_df = pd.read_csv(TEST_FILE)\n",
    "test_df[\"labels\"] = -1\n",
    "test_dataset = make_dataset(test_df, tokenizer, DEVICE)\n",
    "test_dataloader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=VALID_BATCH_SIZE, shuffle=False)\n",
    "\n",
    "with torch.no_grad():\n",
    "    progress = tqdm(test_dataloader, total=len(test_dataloader))\n",
    "    final_output = []\n",
    "\n",
    "    for batch in progress:\n",
    "        progress.set_description(\"<Test>\")\n",
    "\n",
    "        attention_mask, input_ids, labels, token_type_ids = batch.values()\n",
    "\n",
    "        outputs = []\n",
    "        for model in models:\n",
    "            output = model(input_ids, attention_mask, token_type_ids)\n",
    "            outputs.append(output)\n",
    "\n",
    "        outputs = sum(outputs) / len(outputs)\n",
    "        outputs = torch.softmax(outputs, dim=1).cpu().detach().tolist()\n",
    "        outputs = np.argmax(outputs, axis=1)\n",
    "\n",
    "        final_output.extend(outputs)\n",
    "\n",
    "submit = pd.read_csv(os.path.join(data_dir, \"submit_sample.csv\"), names=[\"id\", \"labels\"])\n",
    "submit[\"labels\"] = final_output\n",
    "submit[\"labels\"] = submit[\"labels\"] + 1\n",
    "try:\n",
    "    submit.to_csv(\"./output/Xlnet_submission_cv{}.csv\".format(str(cv).replace(\".\", \"\")[:10]), index=False, header=False)\n",
    "except NameError:\n",
    "    submit.to_csv(\"./output/submission.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9aa1ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n"
     ]
    }
   ],
   "source": [
    "print(\"finish\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb77d44b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
